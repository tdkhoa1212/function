{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Test split() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix: \n",
      " [[0 1 0 0]\n",
      " [0 0 1 0]]\n",
      "\n",
      "############### Print each slice of tensor after using split function ##########\n",
      "\n",
      "Depth number 1:\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "\n",
      "Depth number 2:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "\n",
      "Depth number 3:\n",
      "[[0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "\n",
      "Depth number 4:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "show = False # Turn it to True if you want to plot input data in a image\n",
    "# Input data --------------------------------------------\n",
    "i_matrix = np.array([[0, 1, 0, 0], [0, 0, 1, 0]])\n",
    "print('Original matrix: \\n', i_matrix)\n",
    "if show:\n",
    "    plt.matshow(i_matrix)\n",
    "    plt.title('Original matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Function ----------------------------------------------\n",
    "def split(matrix, depth):\n",
    "    '''\n",
    "    matrix: matrix shape(mxn)\n",
    "    Depth: a number > 1\n",
    "    '''\n",
    "    n_tensor = [] # new created tensor\n",
    "    for i in range(0, depth):\n",
    "        # Creating the padding zero to compensate for the lost path of the shifted matrix\n",
    "        r_matrix = len(matrix)\n",
    "        pad = np.zeros((r_matrix, i))\n",
    "\n",
    "        # 1: a new matrix is generated by concatenate the cut matrix and zero padding\n",
    "        # 2: Collecting new matrices into a tensor\n",
    "        n_tensor.append(np.concatenate((matrix[:, i:], pad), axis=1))\n",
    "    return np.array(n_tensor)\n",
    "\n",
    "# Show each lice of tensor after using split() function\n",
    "print('\\n' + '#'*15 + ' Print each slice of tensor after using split function ' + '#'*10)\n",
    "tensor = split(i_matrix, 4)\n",
    "for idx, i in enumerate(tensor):\n",
    "    print(f'\\nDepth number {idx+1}:')\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Test yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(samples) == end? True\n",
      "[7000, 7000, 7000, 7000, 1376]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def audio_source(name, window):\n",
    "    sample_rate, samples = wavfile.read(name)\n",
    "    begin = 0\n",
    "\n",
    "    while begin < len(samples):\n",
    "        end = min(begin + window, len(samples))\n",
    "        yield samples[begin:end]\n",
    "        begin = end\n",
    "\n",
    "    print('len(samples) == end?', len(samples) == end)\n",
    "\n",
    "# here len(piece) is just for showing each piece\n",
    "generator = [len(piece) for piece in audio_source('wav/apple_and_lemmon.wav', 7000)]\n",
    "print(list(generator))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Test receiver() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min: -15045, max: 15733, length 7000\n",
      "\n",
      "Min: -8768, max: 7947, length 7000\n",
      "\n",
      "Min: -6330, max: 11097, length 7000\n",
      "\n",
      "Min: -5881, max: 10405, length 7000\n",
      "\n",
      "Min: -40, max: 1, length 1376\n",
      "len(samples) == end? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "def audio_source(name, window):\n",
    "    sample_rate, samples = wavfile.read(name)\n",
    "    begin = 0\n",
    "\n",
    "    while begin < len(samples):\n",
    "        end = min(begin + window, len(samples))\n",
    "        yield samples[begin:end]\n",
    "        begin = end\n",
    "\n",
    "    print('len(samples) == end?', len(samples) == end)\n",
    "\n",
    "def min_(data, s=False):\n",
    "    yield np.min(data)\n",
    "\n",
    "def max_(data, i=1):\n",
    "    yield np.max(data)\n",
    "\n",
    "def length_(data):\n",
    "    yield len(data)\n",
    "\n",
    "for data in audio_source('wav/apple_and_lemmon.wav', 7000):\n",
    "    mi = next(min_(data))\n",
    "    ma = next(max_(data))\n",
    "    le = next(length_(data))\n",
    "    print(f'\\nMin: {mi}, max: {ma}, length {le}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Test ma(), stair() and stra() while wav_to_wavelet() using yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of stair segment 1: (269, 11001)\n",
      "Shape of straight segment 1: (269, 11001)\n",
      "\n",
      "the percentage of used RAM:  51.2\n",
      "the percentage of available memory:  48.78864563787238\n",
      "Shape of stair segment 2: (269, 11001)\n",
      "Shape of straight segment 2: (269, 11001)\n",
      "\n",
      "the percentage of used RAM:  51.1\n",
      "the percentage of available memory:  48.85401537853301\n",
      "Shape of stair segment 3: (269, 11001)\n",
      "Shape of straight segment 3: (269, 11001)\n",
      "\n",
      "the percentage of used RAM:  51.2\n",
      "the percentage of available memory:  48.83380141444681\n"
     ]
    }
   ],
   "source": [
    "from utils.tools import stairway, wavelet_to_moving_average, matrix_to_vectors\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from ssqueezepy import ssq_cwt\n",
    "import numpy as np\n",
    "import psutil\n",
    "import soundfile as sf\n",
    "\n",
    "# Get wavelet from .wav file\n",
    "def wav_to_wavelet(path, time_window=0.1):\n",
    "    '''\n",
    "    x: segment data (1D shape)\n",
    "    time_window: time in seconds (s)\n",
    "    '''\n",
    "    track = sf.SoundFile(path)\n",
    "    length = track.frames\n",
    "\n",
    "    can_seek = track.seekable() # To enable access to a file\n",
    "    if not can_seek:\n",
    "        raise ValueError(\"Not compatible with seeking\")\n",
    "\n",
    "    begin = 0\n",
    "    sr = track.samplerate # sample rate\n",
    "    start_frame = sr * begin\n",
    "    sampling_window = int(time_window*sr)\n",
    "    \n",
    "    while begin < length:\n",
    "        # Read and convert .wav file to wavelet\n",
    "        track.seek(start_frame)\n",
    "        audio_section = track.read(sampling_window)\n",
    "        twx, wx, *_ = ssq_cwt(audio_section)  # use wx\n",
    "        yield np.abs(wx)\n",
    "\n",
    "        end = min(begin + sampling_window, length)\n",
    "        begin = end\n",
    "\n",
    "\n",
    "def stra(matrix, dis = 5):\n",
    "    shape = matrix.shape\n",
    "    x, y = matrix_to_vectors(matrix)\n",
    "    x_list = np.array(np.arange(np.min(x), np.max(x), dis))\n",
    "    y_list = np.array(np.arange(np.min(y), np.max(y), dis))\n",
    "    x_1, y_1 = np.meshgrid(x_list, y_list)   # a grid is created by standard straighten\n",
    "\n",
    "    x_train = np.array([x_1[:, i] for i in range(x_1.shape[1])]).reshape(-1, ).astype(np.int32)\n",
    "    y_train = np.array([y_1[:, i] for i in range(y_1.shape[1])]).reshape(-1, )\n",
    "\n",
    "    y_train = np.concatenate((y_train.reshape(-1, 1), x_train.reshape(-1, 1)), axis=-1)\n",
    "    if len(np.unique(x_train)) < 2:\n",
    "        return matrix\n",
    "    ################################### Train with ML ###################################\n",
    "    # This standard data ((y_train, x_train), x_train) is trained with a Machine Learning (ML) model(NearestCentroid). \n",
    "    # After that, using the machine learning\n",
    "    # model predict original data ((y, x), y)\n",
    "    clf = NearestCentroid()\n",
    "    clf.fit(y_train, x_train)\n",
    "    x = clf.predict(np.concatenate((y.reshape(-1, 1), x.reshape(-1, 1)), axis=-1))\n",
    "    return x.reshape(shape)\n",
    "    \n",
    "path = 'wav/apple_and_lemmon.wav'\n",
    "window = 1000 # pooling window in MA function\n",
    "time_window=0.5\n",
    "bins = 10 # number of bins in stairway function\n",
    "dis = 200 # distance between columns in stra function\n",
    "\n",
    "for idx, wx in enumerate(wav_to_wavelet(path, time_window)):\n",
    "    ma_hist = stairway(wavelet_to_moving_average(wx, window), bins)\n",
    "    print(f'Shape of stair segment {idx+1}: {ma_hist.shape}')\n",
    "    ma_hist_stra = stra(ma_hist, dis = dis)\n",
    "    print(f'Shape of straight segment {idx+1}: {ma_hist_stra.shape}\\n')\n",
    "\n",
    "    print('')\n",
    "    print('the percentage of used RAM: ', psutil.virtual_memory().percent)\n",
    "    print('the percentage of available memory: ', psutil.virtual_memory().available * 100 / psutil.virtual_memory().total)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The checking memory function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import linecache\n",
    "import os\n",
    "import tracemalloc\n",
    "\n",
    "def display_top(snapshot, key_type='lineno', limit=3, seg=None):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(f\"Top {limit} lines of segment {seg}\")\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "        filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Check python memory after each piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Python memory after seeking the segment 1--------------------\n",
      "Top 3 lines of segment 1\n",
      "#1: utils\\tools.py:90: 23119.4 KiB\n",
      "    return np.array(all_dig)\n",
      "#2: utils\\tools.py:89: 6.4 KiB\n",
      "    all_dig.append(dig.tolist())\n",
      "#3: ipykernel\\iostream.py:458: 0.1 KiB\n",
      "    def _schedule_in_thread():\n",
      "17 other: 0.8 KiB\n",
      "Total allocated size: 23126.7 KiB\n",
      "--------------------Python memory after seeking the segment 2--------------------\n",
      "Top 3 lines of segment 2\n",
      "#1: _pocketfft\\basic.py:31: 68864.1 KiB\n",
      "    return pfft.c2c(tmp, (axis,), forward, norm, out, workers)\n",
      "#2: utils\\backend.py:38: 25218.8 KiB\n",
      "    return np.zeros(shape, dtype=dtype)\n",
      "#3: utils\\tools.py:90: 23119.4 KiB\n",
      "    return np.array(all_dig)\n",
      "74 other: 12922.8 KiB\n",
      "Total allocated size: 130125.1 KiB\n",
      "--------------------Python memory after seeking the segment 3--------------------\n",
      "Top 3 lines of segment 3\n",
      "#1: _pocketfft\\basic.py:31: 68864.1 KiB\n",
      "    return pfft.c2c(tmp, (axis,), forward, norm, out, workers)\n",
      "#2: utils\\backend.py:38: 25218.8 KiB\n",
      "    return np.zeros(shape, dtype=dtype)\n",
      "#3: utils\\tools.py:90: 23119.4 KiB\n",
      "    return np.array(all_dig)\n",
      "84 other: 12963.3 KiB\n",
      "Total allocated size: 130165.6 KiB\n"
     ]
    }
   ],
   "source": [
    "for idx, wx in enumerate(wav_to_wavelet(path, time_window)):\n",
    "    tracemalloc.start()\n",
    "    ma_hist = stairway(wavelet_to_moving_average(wx, window), bins)\n",
    "    ma_hist_stra = stra(ma_hist, dis = dis)\n",
    "    print('-'*20 + f'Python memory after seeking the segment {idx+1}'+'-'*20)\n",
    "    snapshot = tracemalloc.take_snapshot()\n",
    "    display_top(snapshot, seg=idx+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Check python memory after the last piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Python memory after seeking the last piece ####################\n",
      "Top 3 lines of segment final\n",
      "#1: utils\\tools.py:90: 23119.4 KiB\n",
      "    return np.array(all_dig)\n",
      "#2: ipykernel_4180\\2816025057.py:32: 12609.5 KiB\n",
      "    yield np.abs(wx)\n",
      "#3: lib\\selectors.py:315: 288.1 KiB\n",
      "    r, w, x = select.select(r, w, w, timeout)\n",
      "150 other: 141.1 KiB\n",
      "Total allocated size: 36158.1 KiB\n"
     ]
    }
   ],
   "source": [
    "tracemalloc.start()\n",
    "for idx, wx in enumerate(wav_to_wavelet(path, time_window)):\n",
    "    ma_hist = stairway(wavelet_to_moving_average(wx, window), bins)\n",
    "    ma_hist_stra = stra(ma_hist, dis = dis)\n",
    "    \n",
    "print('#'*20 + ' Python memory after seeking the last piece '+'#'*20)\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "display_top(snapshot, seg='final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the percentage of used RAM:  47.7\n",
      "the percentage of available memory:  52.320493124237004\n"
     ]
    }
   ],
   "source": [
    "assert wx.shape[0] == ma_hist.shape[0], f\"The number of rows in matrices must be equated, but they are {wx.shape[0]} and {ma_hist.shape[0]} of wx and ma_hist respectively\"\n",
    "assert wx.shape[0] == ma_hist_stra.shape[0], f\"The number of rows in matrices must be equated, but they are {wx.shape[0]} and {ma_hist_stra.shape[0]} of wx and ma_hist_stra respectively\"    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/58944777/pytest-is-there-a-way-to-report-memory-usage-of-a-test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f9248da3dea885c0c47324cc0eed29873d6a099e6bea14d89d006c8b04da58f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
